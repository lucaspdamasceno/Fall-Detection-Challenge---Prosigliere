# -*- coding: utf-8 -*-
"""Fall Detection Challenge - Complete Solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BhQoFRp7ROBaNcyknIxFcYMhAIncdgFA
"""

#!pip install tensorflow pandas numpy scikit-learn matplotlib seaborn scipy imbalanced-learn google-generativeai openpyxl

import zipfile
import os

# Caminho para o arquivo ZIP
zip_path = "AI_ML_Challenge-20250925T215710Z-1-001.zip"

# Pasta de destino onde os arquivos serão extraídos
extract_path = "AI_ML_Challenge-Data"

# Cria a pasta se não existir
os.makedirs(extract_path, exist_ok=True)

# Extraindo o ZIP
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Arquivos extraídos para: {extract_path}")

"""
Fall Detection Challenge - Complete Solution
Author: Lucas Damasceno
Date: 09/26/2025

This script implements a comprehensive fall detection system using IMU sensor data.
It includes data preprocessing, multiple model architectures, and Gemini integration for explainability.
"""

import os
import numpy as np
import pandas as pd
import pickle
import time
import warnings
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import json
from pathlib import Path

# Data processing and visualization
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import signal
from scipy.stats import skew, kurtosis

# Machine Learning
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, confusion_matrix, classification_report,
                           roc_auc_score, roc_curve)
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE

# Deep Learning
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.layers import (LSTM, GRU, Dense, Dropout, BatchNormalization,
                                   Input, Bidirectional, GlobalAveragePooling1D,
                                   MultiHeadAttention, LayerNormalization)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Google Gemini Integration (optional)
try:
    import google.generativeai as genai
except ImportError:
    genai = None
    print("Warning: google.generativeai not installed. Gemini integration disabled.")

warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

class FallDetectionPipeline:
    """
    Main pipeline for fall detection using IMU sensor data.
    Handles data loading, preprocessing, model training, and evaluation.
    """

    def __init__(self, data_path: str, gemini_api_key: Optional[str] = None):
        """
        Initialize the fall detection pipeline.

        Args:
            data_path: Path to the main data directory
            gemini_api_key: API key for Google Gemini (optional)
        """
        self.data_path = Path(data_path)
        self.gemini_api_key = gemini_api_key
        self.sensor_locations = ['r.ankle', 'l.ankle', 'r.thigh', 'l.thigh',
                                'head', 'sternum', 'waist']
        self.sensor_types = ['Acceleration', 'Angular Velocity', 'Magnetic Field']
        self.axes = ['X', 'Y', 'Z']

        # Storage for results
        self.results = {
            'general_model': {},
            'subject_models': {},
            'timing_info': {},
            'feature_importance': {}
        }

        # Initialize Gemini if API key provided
        if gemini_api_key and genai:
            try:
                genai.configure(api_key=gemini_api_key)
                self.gemini_model = genai.GenerativeModel('gemini-2.5-pro')
            except Exception as e:
                print(f"Warning: Could not initialize Gemini: {e}")
                self.gemini_model = None
        else:
            self.gemini_model = None

    def load_single_file(self, filepath: Path) -> pd.DataFrame:
        """Load a single Excel file and return as DataFrame."""
        try:
            df = pd.read_excel(filepath, engine='openpyxl')
            return df
        except Exception as e:
            print(f"Error loading {filepath}: {e}")
            return None

    def load_subject_data(self, subject_folder: str, max_files_per_category: int = 4) -> Dict:
        """
        Load data for a single subject with limited files per category.

        Args:
            subject_folder: Name of subject folder (e.g., 'sub1')
            max_files_per_category: Maximum files to load per category

        Returns:
            Dictionary with loaded data and labels
        """
        subject_path = self.data_path / subject_folder
        data_dict = {'data': [], 'labels': [], 'filenames': []}

        categories = {
            'ADLs': 0,
            'Falls': 1,
            'Near_Falls': 2
        }

        for category, label in categories.items():
            category_path = subject_path / category
            if not category_path.exists():
                print(f"Warning: {category_path} does not exist")
                continue

            files = list(category_path.glob('*.xlsx'))[:max_files_per_category]

            for file in files:
                df = self.load_single_file(file)
                if df is not None:
                    data_dict['data'].append(df)
                    data_dict['labels'].append(label)
                    data_dict['filenames'].append(str(file))

        print(f"Loaded {len(data_dict['data'])} files from {subject_folder}")
        return data_dict

    def extract_features(self, df: pd.DataFrame) -> np.ndarray:
        """
        Extract features from raw sensor data.

        Args:
            df: DataFrame with sensor readings

        Returns:
            Feature array
        """
        features = []

        for location in self.sensor_locations:
            for sensor_type in self.sensor_types:
                for axis in self.axes:
                    col_name = f"{location} {sensor_type} {axis}"

                    # Handle different column naming conventions
                    if sensor_type == 'Acceleration':
                        col_name = f"{location} {sensor_type} {axis} (m/s^2)"
                    elif sensor_type == 'Angular Velocity':
                        col_name = f"{location} {sensor_type} {axis} (rad/s)"
                    elif sensor_type == 'Magnetic Field':
                        col_name = f"{location} {sensor_type} {axis} (uT)"

                    if col_name in df.columns:
                        signal_data = df[col_name].values

                        # Handle NaN values
                        signal_data = np.nan_to_num(signal_data, nan=0.0)

                        # Time domain features
                        features.extend([
                            np.mean(signal_data),
                            np.std(signal_data),
                            np.max(signal_data),
                            np.min(signal_data),
                            np.percentile(signal_data, 25),
                            np.percentile(signal_data, 75),
                            skew(signal_data),
                            kurtosis(signal_data)
                        ])

                        # Frequency domain features (if enough samples)
                        if len(signal_data) > 10:
                            fft_vals = np.abs(np.fft.fft(signal_data))[:len(signal_data)//2]
                            features.extend([
                                np.mean(fft_vals),
                                np.std(fft_vals),
                                np.max(fft_vals)
                            ])
                        else:
                            features.extend([0, 0, 0])

        # Calculate magnitude features for acceleration and angular velocity
        for location in self.sensor_locations:
            acc_cols = [f"{location} Acceleration {axis} (m/s^2)" for axis in self.axes]
            gyro_cols = [f"{location} Angular Velocity {axis} (rad/s)" for axis in self.axes]

            # Acceleration magnitude
            if all(col in df.columns for col in acc_cols):
                acc_mag = np.sqrt(df[acc_cols[0]]**2 + df[acc_cols[1]]**2 + df[acc_cols[2]]**2)
                features.extend([
                    np.mean(acc_mag),
                    np.std(acc_mag),
                    np.max(acc_mag),
                    np.min(acc_mag)
                ])
            else:
                features.extend([0, 0, 0, 0])

            # Angular velocity magnitude
            if all(col in df.columns for col in gyro_cols):
                gyro_mag = np.sqrt(df[gyro_cols[0]]**2 + df[gyro_cols[1]]**2 + df[gyro_cols[2]]**2)
                features.extend([
                    np.mean(gyro_mag),
                    np.std(gyro_mag),
                    np.max(gyro_mag),
                    np.min(gyro_mag)
                ])
            else:
                features.extend([0, 0, 0, 0])

        return np.array(features)

    def create_sequences(self, df: pd.DataFrame, sequence_length: int = 50,
                        use_pca: bool = False, pca_model: Optional[PCA] = None,
                        scaler_model: Optional[StandardScaler] = None,
                        n_components: int = 30) -> Tuple[np.ndarray, Optional[PCA], Optional[StandardScaler]]:
        """
        Create sequences for time-series models with optional PCA.

        Args:
            df: DataFrame with sensor data
            sequence_length: Length of each sequence
            use_pca: Whether to apply PCA
            pca_model: Pre-fitted PCA model (for test data)
            scaler_model: Pre-fitted scaler model (for test data)
            n_components: Number of PCA components

        Returns:
            Tuple of (sequences array, fitted pca model, fitted scaler model)
        """
        # Select only sensor columns
        sensor_cols = []
        for location in self.sensor_locations:
            for sensor_type in self.sensor_types:
                for axis in self.axes:
                    if sensor_type == 'Acceleration':
                        col_name = f"{location} {sensor_type} {axis} (m/s^2)"
                    elif sensor_type == 'Angular Velocity':
                        col_name = f"{location} {sensor_type} {axis} (rad/s)"
                    elif sensor_type == 'Magnetic Field':
                        col_name = f"{location} {sensor_type} {axis} (uT)"

                    if col_name in df.columns:
                        sensor_cols.append(col_name)

        data = df[sensor_cols].values
        data = np.nan_to_num(data, nan=0.0)

        # Apply PCA if requested
        if use_pca:
            # Standardize data
            if scaler_model is None:
                scaler_model = StandardScaler()
                data_scaled = scaler_model.fit_transform(data)
            else:
                data_scaled = scaler_model.transform(data)

            # Apply PCA
            if pca_model is None:
                # Determine valid number of components
                max_components = min(data_scaled.shape[0] - 1, data_scaled.shape[1] - 1, n_components)
                if max_components < 2:
                    print(f"Warning: Not enough samples for PCA. Using original features.")
                    data_transformed = data_scaled
                else:
                    pca_model = PCA(n_components=max_components)
                    data_transformed = pca_model.fit_transform(data_scaled)
                    explained_var = sum(pca_model.explained_variance_ratio_)
                    print(f"PCA on sequences: {len(sensor_cols)} → {max_components} features (explained var: {explained_var:.3f})")
            else:
                data_transformed = pca_model.transform(data_scaled)

            data = data_transformed

        # Create sliding window sequences
        sequences = []
        for i in range(0, len(data) - sequence_length + 1, sequence_length // 2):
            sequences.append(data[i:i + sequence_length])

        if len(sequences) == 0:  # If data is too short, pad it
            padded = np.zeros((sequence_length, data.shape[1]))
            padded[:len(data)] = data
            sequences.append(padded)

        return np.array(sequences), pca_model, scaler_model

    def preprocess_data(self, data_dict: Dict, use_pca: bool = False,
                       n_components: int = 50) -> Tuple[np.ndarray, np.ndarray]:
        """
        Preprocess data with optional PCA for dimensionality reduction.

        Args:
            data_dict: Dictionary with data and labels
            use_pca: Whether to apply PCA
            n_components: Number of PCA components

        Returns:
            Preprocessed features and labels
        """
        features_list = []
        labels_list = []

        for df, label in zip(data_dict['data'], data_dict['labels']):
            features = self.extract_features(df)
            features_list.append(features)
            labels_list.append(label)

        X = np.array(features_list)
        y = np.array(labels_list)

        # Handle NaN and infinite values
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

        # Standardization
        scaler = StandardScaler()
        X = scaler.fit_transform(X)

        # PCA if requested
        if use_pca:
            # Adjust n_components to be valid
            max_components = min(X.shape[0], X.shape[1]) - 1
            n_components_adjusted = min(n_components, max_components)

            if n_components_adjusted < 2:
                print(f"Warning: Not enough samples/features for PCA. Skipping PCA.")
                return X, y

            pca = PCA(n_components=n_components_adjusted)
            X_pca = pca.fit_transform(X)
            print(f"PCA: Reduced dimensions from {X.shape[1]} to {n_components_adjusted}")
            print(f"Explained variance ratio: {sum(pca.explained_variance_ratio_):.3f}")
            return X_pca, y

        return X, y

    def create_lstm_model(self, input_shape: Tuple, num_classes: int = 3) -> keras.Model:
        """Create LSTM model for fall detection."""
        model = models.Sequential([
            layers.Input(shape=input_shape),
            layers.LSTM(128, return_sequences=True),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.LSTM(64, return_sequences=True),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.LSTM(32),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(num_classes, activation='softmax')
        ])

        model.compile(
            optimizer=optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        return model

    def create_gru_model(self, input_shape: Tuple, num_classes: int = 3) -> keras.Model:
        """Create GRU model for fall detection."""
        model = models.Sequential([
            layers.Input(shape=input_shape),
            layers.GRU(128, return_sequences=True),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.GRU(64, return_sequences=True),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.GRU(32),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(num_classes, activation='softmax')
        ])

        model.compile(
            optimizer=optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        return model

    def create_transformer_model(self, input_shape: Tuple, num_classes: int = 3) -> keras.Model:
        """Create Transformer model for fall detection."""
        inputs = layers.Input(shape=input_shape)

        # Positional encoding
        positions = tf.range(start=0, limit=input_shape[0], delta=1)
        position_embedding = layers.Embedding(input_dim=input_shape[0],
                                             output_dim=input_shape[1])(positions)

        x = inputs + position_embedding

        # Transformer blocks
        for _ in range(2):
            # Multi-head attention
            attn_output = layers.MultiHeadAttention(
                num_heads=4,
                key_dim=input_shape[1]//4
            )(x, x)
            attn_output = layers.Dropout(0.2)(attn_output)
            x = layers.LayerNormalization()(x + attn_output)

            # Feed-forward network
            ff_output = layers.Dense(128, activation='relu')(x)
            ff_output = layers.Dense(input_shape[1])(ff_output)
            ff_output = layers.Dropout(0.2)(ff_output)
            x = layers.LayerNormalization()(x + ff_output)

        # Global pooling and classification
        x = layers.GlobalAveragePooling1D()(x)
        x = layers.Dense(64, activation='relu')(x)
        x = layers.Dropout(0.3)(x)
        outputs = layers.Dense(num_classes, activation='softmax')(x)

        model = models.Model(inputs=inputs, outputs=outputs)

        model.compile(
            optimizer=optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        return model

    def train_model(self, model: keras.Model, X_train: np.ndarray, y_train: np.ndarray,
                   X_val: np.ndarray, y_val: np.ndarray,
                   model_name: str = "model") -> Dict:
        """
        Train a model and record timing information.

        Returns:
            Dictionary with training history and timing
        """
        # Callbacks
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True
        )

        reduce_lr = ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=0.00001
        )

        # Train model
        start_time = time.time()

        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=100,
            batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=0,
            class_weight=self.calculate_class_weights(y_train)
        )

        training_time = time.time() - start_time

        return {
            'history': history.history,
            'training_time': training_time,
            'model': model
        }

    def calculate_class_weights(self, y_train: np.ndarray) -> Dict:
        """Calculate class weights for imbalanced data."""
        if len(y_train.shape) > 1:  # If one-hot encoded
            y_train_labels = np.argmax(y_train, axis=1)
        else:
            y_train_labels = y_train

        unique_classes = np.unique(y_train_labels)
        class_weights = compute_class_weight(
            'balanced',
            classes=unique_classes,
            y=y_train_labels
        )

        return dict(zip(unique_classes, class_weights))

    def evaluate_model(self, model: keras.Model, X_test: np.ndarray,
                      y_test: np.ndarray, model_name: str = "model") -> Dict:
        """
        Evaluate model performance.

        Returns:
            Dictionary with evaluation metrics
        """
        start_time = time.time()

        # Predictions
        y_pred_proba = model.predict(X_test, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)

        if len(y_test.shape) > 1:  # If one-hot encoded
            y_true = np.argmax(y_test, axis=1)
        else:
            y_true = y_test

        prediction_time = time.time() - start_time

        # Calculate metrics
        metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, average='weighted'),
            'recall': recall_score(y_true, y_pred, average='weighted'),
            'f1_score': f1_score(y_true, y_pred, average='weighted'),
            'prediction_time': prediction_time,
            'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),
            'classification_report': classification_report(
                y_true, y_pred,
                target_names=['ADLs', 'Falls', 'Near_Falls']
            )
        }

        return metrics

    def run_experiment(self, subject_id: Optional[str] = None,
                      use_pca: bool = False) -> Dict:
        """
        Run complete experiment for either a specific subject or all subjects.

        Args:
            subject_id: Specific subject ID (e.g., 'sub1') or None for all
            use_pca: Whether to use PCA for dimensionality reduction

        Returns:
            Dictionary with all results
        """
        results = {
            'models': {},
            'metrics': {},
            'timing': {}
        }

        # Load data
        if subject_id:
            print(f"\n{'='*50}")
            print(f"Training model for {subject_id}")
            print(f"{'='*50}")
            data_dict = self.load_subject_data(subject_id)
            experiment_name = f"{subject_id}_{'pca' if use_pca else 'no_pca'}"
        else:
            print(f"\n{'='*50}")
            print(f"Training general model (all subjects)")
            print(f"{'='*50}")

            # Load data from multiple subjects (up to 4 files per category per subject)
            all_data = {'data': [], 'labels': [], 'filenames': []}
            subjects = [f'sub{i}' for i in range(1, 9)]

            for sub in subjects:
                if (self.data_path / sub).exists():
                    sub_data = self.load_subject_data(sub, max_files_per_category=4)
                    all_data['data'].extend(sub_data['data'])
                    all_data['labels'].extend(sub_data['labels'])
                    all_data['filenames'].extend(sub_data['filenames'])

            data_dict = all_data
            experiment_name = f"general_{'pca' if use_pca else 'no_pca'}"

        print(f"Total samples loaded: {len(data_dict['data'])}")

        # Check if we have enough data
        if len(data_dict['data']) < 10:
            print(f"Warning: Not enough data samples ({len(data_dict['data'])} < 10). Skipping experiment.")
            return results

        # Create sequences for time-series models WITH PCA if requested
        sequences_list = []
        labels_list = []

        # Initialize PCA and scaler models (will be fitted on first batch)
        pca_model = None
        scaler_model = None

        print(f"\nCreating sequences (PCA={'ON' if use_pca else 'OFF'})...")

        for idx, (df, label) in enumerate(zip(data_dict['data'], data_dict['labels'])):
            # Create sequences with optional PCA
            sequences, pca_model, scaler_model = self.create_sequences(
                df,
                sequence_length=50,
                use_pca=use_pca,
                pca_model=pca_model,  # Use fitted model after first iteration
                scaler_model=scaler_model,
                n_components=30  # Reduce from 63 to 30 features if using PCA
            )

            for seq in sequences:
                sequences_list.append(seq)
                labels_list.append(label)

        if len(sequences_list) == 0:
            print("Warning: No valid sequences created. Skipping experiment.")
            return results

        X_sequences = np.array(sequences_list)
        y_sequences = np.array(labels_list)

        print(f"\nTotal sequences created: {len(X_sequences)}")
        print(f"Sequence shape: {X_sequences.shape}")

        if use_pca:
            print(f"✓ PCA Applied: Features reduced from 63 to {X_sequences.shape[2]}")
        else:
            print(f"✓ No PCA: Using all {X_sequences.shape[2]} original features")

        # Check class distribution
        unique, counts = np.unique(y_sequences, return_counts=True)
        print(f"\nClass distribution: {dict(zip(unique, counts))}")

        # Check if we have all classes
        if len(unique) < 3:
            print(f"Warning: Only {len(unique)} classes found. Need 3 classes. Skipping experiment.")
            return results

        # Convert labels to categorical
        y_sequences_cat = to_categorical(y_sequences, num_classes=3)

        # Split data - ensure minimum samples
        if len(X_sequences) < 15:
            print(f"Warning: Not enough sequences ({len(X_sequences)} < 15) for proper split. Skipping experiment.")
            return results

        try:
            X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(
                X_sequences, y_sequences_cat, test_size=0.2, random_state=42, stratify=y_sequences
            )

            X_seq_train, X_seq_val, y_seq_train, y_seq_val = train_test_split(
                X_seq_train, y_seq_train, test_size=0.2, random_state=42
            )
        except ValueError as e:
            print(f"Error splitting data: {e}")
            print("This usually happens when there aren't enough samples per class.")
            return results

        print(f"\nData split completed:")
        print(f"  Training set:   {X_seq_train.shape} ({len(X_seq_train)} samples)")
        print(f"  Validation set: {X_seq_val.shape} ({len(X_seq_val)} samples)")
        print(f"  Test set:       {X_seq_test.shape} ({len(X_seq_test)} samples)")

        # Define models to test
        models_to_test = {
            'LSTM': self.create_lstm_model,
            'GRU': self.create_gru_model,
            'Transformer': self.create_transformer_model
        }

        # Train and evaluate each model
        for model_name, model_creator in models_to_test.items():
            print(f"\n{'='*50}")
            print(f"Training {model_name} model...")
            print(f"{'='*50}")

            try:
                # Create model with correct input shape
                model = model_creator(
                    input_shape=(X_seq_train.shape[1], X_seq_train.shape[2]),
                    num_classes=3
                )

                print(f"Model created with input shape: ({X_seq_train.shape[1]}, {X_seq_train.shape[2]})")

                # Train model
                train_results = self.train_model(
                    model, X_seq_train, y_seq_train,
                    X_seq_val, y_seq_val,
                    model_name=f"{experiment_name}_{model_name}"
                )

                # Evaluate model
                eval_results = self.evaluate_model(
                    train_results['model'],
                    X_seq_test, y_seq_test,
                    model_name=f"{experiment_name}_{model_name}"
                )

                # Store results
                results['models'][model_name] = train_results['model']
                results['metrics'][model_name] = eval_results
                results['timing'][model_name] = {
                    'training_time': train_results['training_time'],
                    'prediction_time': eval_results['prediction_time'],
                    'total_time': train_results['training_time'] + eval_results['prediction_time']
                }

                # Print results
                print(f"\n{model_name} Results:")
                print(f"  Accuracy:  {eval_results['accuracy']:.4f}")
                print(f"  Precision: {eval_results['precision']:.4f}")
                print(f"  Recall:    {eval_results['recall']:.4f}")
                print(f"  F1-Score:  {eval_results['f1_score']:.4f}")
                print(f"  Training Time:   {train_results['training_time']:.2f}s")
                print(f"  Prediction Time: {eval_results['prediction_time']:.4f}s")

                # Show confusion matrix
                print(f"\nConfusion Matrix:")
                cm = eval_results['confusion_matrix']
                print("          Predicted")
                print("          ADL  Fall  Near")
                for i, row in enumerate(cm):
                    label = ['ADL ', 'Fall', 'Near'][i]
                    print(f"Actual {label}: {row}")

            except Exception as e:
                print(f"Error training {model_name}: {e}")
                continue

        # Save storage info about PCA
        if use_pca and pca_model:
            results['pca_info'] = {
                'n_components': pca_model.n_components_,
                'original_features': 63,
                'reduced_features': X_sequences.shape[2]
            }

        return results

    def compare_models(self, results_dict: Dict) -> pd.DataFrame:
        """
        Create comparison table for all models.

        Returns:
            DataFrame with model comparison
        """
        comparison_data = []

        for experiment_name, results in results_dict.items():
            if 'metrics' in results and results['metrics']:  # Check if metrics exist
                for model_name in results['metrics'].keys():
                    comparison_data.append({
                        'Experiment': experiment_name,
                        'Model': model_name,
                        'Accuracy': results['metrics'][model_name]['accuracy'],
                        'Precision': results['metrics'][model_name]['precision'],
                        'Recall': results['metrics'][model_name]['recall'],
                        'F1-Score': results['metrics'][model_name]['f1_score'],
                        'Training Time (s)': results['timing'][model_name]['training_time'],
                        'Prediction Time (s)': results['timing'][model_name]['prediction_time'],
                        'Total Time (s)': results['timing'][model_name]['total_time']
                    })

                    # Add PCA info if available
                    if 'pca_info' in results:
                        comparison_data[-1]['Features'] = results['pca_info']['reduced_features']
                    else:
                        comparison_data[-1]['Features'] = 63  # Original features

        if comparison_data:
            df_comparison = pd.DataFrame(comparison_data)
            # Sort by F1-Score descending
            df_comparison = df_comparison.sort_values('F1-Score', ascending=False)
            return df_comparison
        else:
            print("Warning: No valid results to compare")
            return pd.DataFrame()

    def generate_final_report_with_gemini(self, all_results: Dict) -> str:
        """
        Generate comprehensive final report using Gemini AI.

        Returns:
            Formatted report string
        """
        # First create a traditional comparison table
        comparison_df = self.compare_models(all_results)

        if comparison_df.empty:
            return "No valid results to generate report."

        # If Gemini is not available, fall back to basic report
        if not self.gemini_model:
            print("Warning: Gemini not available. Generating basic report.")
            return self._generate_basic_report(all_results, comparison_df)

        # Prepare comprehensive data for Gemini
        results_summary = {
            'total_experiments': len(all_results),
            'experiments': {}
        }

        for exp_name, exp_results in all_results.items():
            if 'metrics' in exp_results and exp_results['metrics']:
                exp_summary = {
                    'models': {},
                    'pca_used': 'pca' in exp_name,
                    'subject_specific': not exp_name.startswith('general')
                }

                for model_name, metrics in exp_results['metrics'].items():
                    exp_summary['models'][model_name] = {
                        'accuracy': metrics['accuracy'],
                        'precision': metrics['precision'],
                        'recall': metrics['recall'],
                        'f1_score': metrics['f1_score'],
                        'training_time': exp_results['timing'][model_name]['training_time'],
                        'confusion_matrix': metrics['confusion_matrix']
                    }

                results_summary['experiments'][exp_name] = exp_summary

        # Create prompt for Gemini
        prompt = f"""
        You are an AI expert specialized in machine learning and fall detection systems.
        Please generate a comprehensive technical report based on the following experimental results.

        ## Experimental Results Data:
        {json.dumps(results_summary, indent=2)}

        ## Model Performance Table:
        {comparison_df.to_string()}

        Please create a detailed report that includes:

        1. **Executive Summary**: Brief overview of the challenge and key findings

        2. **Performance Analysis**:
           - Best performing model overall
           - Comparison between LSTM, GRU, and Transformer architectures
           - Statistical significance of differences

        3. **Subject-Specific vs General Models**:
           - Compare performance between models trained on individual subjects vs all subjects
           - Analyze if personalized models show better performance
           - Discuss implications for real-world deployment

        4. **Impact of Dimensionality Reduction (PCA)**:
           - Quantify the trade-off between computational efficiency and accuracy
           - Calculate percentage improvements in training time
           - Assess if the accuracy loss is acceptable

        5. **Cross-Subject Variability**:
           - Analyze performance differences between sub1 and sub2 models
           - Discuss how individual movement patterns affect model accuracy
           - Implications for model generalization

        6. **Clinical Relevance**:
           - Interpret confusion matrices for medical implications
           - Discuss false positive vs false negative trade-offs
           - Recommendations for clinical deployment

        7. **Technical Recommendations**:
           - Which model architecture to deploy
           - Whether to use PCA in production
           - Whether to use general or personalized models
           - Suggested improvements for future iterations

        8. **Conclusion**:
           - Key takeaways
           - Limitations of current approach
           - Future research directions

        Format the report professionally with clear sections, bullet points where appropriate,
        and specific metrics to support all claims. Make it technical but accessible to
        both ML engineers and healthcare professionals.

        Length: Approximately 800-1000 words.
        """

        try:
            print("Generating comprehensive report with Gemini AI...")
            response = self.gemini_model.generate_content(prompt)

            # Add header and footer
            report = []
            report.append("="*80)
            report.append("FALL DETECTION CHALLENGE - AI-GENERATED COMPREHENSIVE REPORT")
            report.append("="*80)
            report.append(f"\nReport Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report.append("Powered by Google Gemini AI\n")
            report.append("="*80)
            report.append("\n")
            report.append(response.text)
            report.append("\n")
            report.append("="*80)
            report.append("END OF AI-GENERATED REPORT")
            report.append("="*80)

            return "\n".join(report)

        except Exception as e:
            print(f"Error generating report with Gemini: {e}")
            print("Falling back to basic report.")
            return self._generate_basic_report(all_results, comparison_df)

    def _generate_basic_report(self, all_results: Dict, comparison_df: pd.DataFrame) -> str:
        """
        Generate basic report without Gemini.
        """
        report = []
        report.append("="*80)
        report.append("FALL DETECTION CHALLENGE - FINAL REPORT")
        report.append("="*80)
        report.append(f"\nReport Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        report.append("\n" + "="*80)
        report.append("MODEL PERFORMANCE SUMMARY")
        report.append("="*80)
        report.append("\n" + comparison_df.to_string(index=False))

        # Best model
        best_idx = comparison_df['F1-Score'].idxmax()
        best_model = comparison_df.iloc[best_idx]

        return "\n".join(report)

def main():
    """
    Main execution function.
    """
    print("="*80)
    print("FALL DETECTION CHALLENGE - COMPLETE SOLUTION")
    print("="*80)

    # Configuration
    DATA_PATH = "AI_ML_Challenge-Data/AI_ML_Challenge"  # Update this path
    GEMINI_API_KEY = "AIzaSyD8jQqK1JIYdR9OOzS_X8_NYpkwyL_-0og" # API key provided only for this challenge. It may not work properly. Note: hardcoding API keys directly in code is not a good practice.

    # Initialize pipeline
    pipeline = FallDetectionPipeline(DATA_PATH, GEMINI_API_KEY)

    # Store all results
    all_results = {}

    # 1. Train General Model (without PCA)
    print("\n" + "="*80)
    print("EXPERIMENT 1: General Model (No PCA)")
    print("="*80)
    general_results_no_pca = pipeline.run_experiment(subject_id=None, use_pca=False)
    all_results['general_no_pca'] = general_results_no_pca

    # 2. Train General Model (with PCA)
    print("\n" + "="*80)
    print("EXPERIMENT 2: General Model (With PCA)")
    print("="*80)
    general_results_pca = pipeline.run_experiment(subject_id=None, use_pca=True)
    all_results['general_pca'] = general_results_pca

    # 3. Train Subject-Specific Model - Subject 1 (No PCA)
    print("\n" + "="*80)
    print("EXPERIMENT 3: Subject-Specific Model - Subject 1 (No PCA)")
    print("="*80)
    if (Path(DATA_PATH) / 'sub1').exists():
        sub1_results_no_pca = pipeline.run_experiment(subject_id='sub1', use_pca=False)
        all_results['sub1_no_pca'] = sub1_results_no_pca

    # 4. Train Subject-Specific Model - Subject 2 (No PCA)
    print("\n" + "="*80)
    print("EXPERIMENT 5: Subject-Specific Model - Subject 2 (No PCA)")
    print("="*80)
    if (Path(DATA_PATH) / 'sub2').exists():
        sub2_results_no_pca = pipeline.run_experiment(subject_id='sub2', use_pca=False)
        all_results['sub2_no_pca'] = sub2_results_no_pca

    # Compare Subject 1 vs Subject 2 performance
    print("\n" + "="*80)
    print("SUBJECT COMPARISON ANALYSIS")
    print("="*80)

    if 'sub1_no_pca' in all_results and 'sub2_no_pca' in all_results:
        if all_results['sub1_no_pca']['metrics'] and all_results['sub2_no_pca']['metrics']:
            print("\nComparing Subject 1 vs Subject 2 (No PCA):")
            for model_name in ['LSTM', 'GRU', 'Transformer']:
                if model_name in all_results['sub1_no_pca']['metrics'] and \
                   model_name in all_results['sub2_no_pca']['metrics']:
                    sub1_f1 = all_results['sub1_no_pca']['metrics'][model_name]['f1_score']
                    sub2_f1 = all_results['sub2_no_pca']['metrics'][model_name]['f1_score']
                    diff = abs(sub1_f1 - sub2_f1) * 100
                    print(f"\n{model_name}:")
                    print(f"  Subject 1 F1-Score: {sub1_f1:.4f}")
                    print(f"  Subject 2 F1-Score: {sub2_f1:.4f}")
                    print(f"  Difference: {diff:.1f}%")

                    if diff > 5:
                        print(f"  ⚠ Significant variation detected!")
                        print(f"    This suggests individual movement patterns affect model accuracy")

    # Generate final report with Gemini
    print("\n" + "="*80)
    print("GENERATING COMPREHENSIVE AI REPORT")
    print("="*80)

    final_report = pipeline.generate_final_report_with_gemini(all_results)
    print(final_report)

    # Save report to file
    report_filename = f"fall_detection_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_filename, 'w') as f:
        f.write(final_report)
    print(f"\n✓ Report saved to {report_filename}")

    print("\n" + "="*80)
    print("FALL DETECTION CHALLENGE COMPLETED SUCCESSFULLY")
    print("="*80)

if __name__ == "__main__":
    main()

